% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/semtree.R
\name{semtree}
\alias{semtree}
\alias{plot.semtree}
\alias{print.semtree}
\alias{summary.semtree}
\alias{toLatex.semtree}
\alias{nodeFunSemtree}
\title{SEM Tree: Recursive Partitioning for Structural Equation Models}
\usage{
semtree(
  model,
  data = NULL,
  control = NULL,
  constraints = NULL,
  predictors = NULL,
  ...
)
}
\arguments{
\item{model}{A template model specification from \pkg{OpenMx} using
the \code{\link[OpenMx]{mxModel}} function or a \pkg{lavaan} model
using the \code{\link[lavaan]{lavaan}} function with option do.fit=FALSE).
Model must be syntactically correct within the framework chosen, and
converge to a solution.}

\item{data}{A \code{data.frame} used for building the tree. Order
of modeled variables and predictors is not important when providing a
dataset to \code{semtree}.}

\item{control}{\code{\link{semtree}} model specifications from
\code{\link{semtree.control}} are input here. Any changes from the default
setting can be specified here.}

\item{constraints}{A \code{\link{semtree.constraints}} object setting model
parameters as constrained from the beginning of the \code{semtree}
computation. This includes options to globally or locally set equality
constraints and to specify focus parameters (i.e., parameter subsets that
exclusively go into the function evaluating splits). Also, options for
measurement invariance testing in trees are included.}

\item{predictors}{A vector of variable names matching variable names in
data set. If NULL (default) all variables that are in data set and not part of
the model are potential predictors. Optional function input to select a
subset of the unmodeled variables to use as predictors in the \code{semtree}
function.}

\item{\dots}{Optional arguments passed to the tree growing function.}
}
\value{
A \code{semtree} object is created which can be examined with
\code{summary}, \code{plot}, and \code{print}.
}
\description{
Structural equation model (SEM) trees combine SEM with decision-trees (a paradigm also known as
recursive partitioning).
}
\details{
Core idea:
Instead of assuming that one SEM fits all individuals equally well, SEM Trees recursively split the sample into subgroups based on covariates (e.g., age, gender, SES) such that model parameters differ between subgroups.
This results in a tree where each node contains an SEM, revealing heterogeneity in model structure or parameters across groups.

The package supports model specification in lavaan and OpenMx.


Calling \code{semtree} with an \code{\link[OpenMx]{mxModel}} or
\code{\link[lavaan]{lavaan}} model fits the template to the data set provided and
then recurses over the following steps until no further meaningful partition
into sub groups is found:
\enumerate{
  \item Fit the model on the current node's data and compute the model fit.
  \item For each predictor, generate candidate split points (or score tests)
  and estimate the improvement in model fit using the chosen method in
  \code{\link{semtree.control}}.
  \item Select the best-performing predictor/split combination and apply it
  when it passes the statistical threshold (\code{alpha}) and satisfies the
  size limitations (\code{min.N}, \code{min.bucket}, \code{max.depth}, or a
  custom stopping rule).
  \item Continue the procedure independently on each resulting child node so
  that terminal nodes (leafs) contain SEMs with subgroup-specific parameter
  estimates.
}

Predictors can be categorical (ordered or unordered) or continuous. When
using unordered categorical predictors with many levels, the number of
candidate partitions grows quickly, so limiting the predictor set can reduce
computation and the number of multiple comparisons.

Splitting quality can be evaluated with three built-in strategies:

1. "naive" selection compares all possible split values across all
predictors and chooses the best overall improvement.

2. "fair" selection uses a two-step procedure at each node: a first phase on
half the sample identifies the best split value per predictor, and a second
phase on the remaining data picks the most promising predictor among those
candidates.

3. "score" relies on score-based statistics that provide faster evaluations
while retaining favorable statistical properties for detecting parameter
instabilities.

All other parameters controlling the tree growing process are adjusted
in the \code{\link{semtree.control}} object.

In order to get robust estimates of the importance of predictors,
consider growing a \code{\link{semforest}}
}
\references{
Brandmaier, A.M., Oertzen, T. v., McArdle, J.J., & Lindenberger, U. (2013). Structural equation model trees. \emph{Psychological Methods}, 18(1), 71-86.

Arnold, M., Voelkle, M. C., & Brandmaier, A. M. (2021). Score-guided structural equation model trees. \emph{Frontiers in Psychology}, 11, Article 564403. https://doi.org/10.3389/fpsyg.2020.564403
}
\seealso{
\code{\link{semtree.control}}, \code{\link{summary.semtree}},
\code{\link{parameters}}, \code{\link{se}}, \code{\link{prune.semtree}},
\code{\link{subtree}}, \code{\link[OpenMx]{OpenMx}},
\code{\link[lavaan]{lavaan}}
}
\author{
Andreas M. Brandmaier, John J. Prindle, Manuel Arnold
}
\keyword{models}
\keyword{multivariate}
\keyword{tree}
